# Copyright 2025 GlyphyAI
#
# Use of this source code is governed by an MIT-style
# license that can be found in the LICENSE file or at
# https://opensource.org/licenses/MIT.

from pydantic import BaseModel

from liteswarm.types.swarm import Agent, AgentResponse, Message


class ChatResponse(BaseModel):
    """Response object containing execution results and conversation state.

    Encapsulates the complete state of a chat interaction, including the final
    agent that responded, new messages generated during execution, the complete
    conversation history, and all intermediate agent responses. This object
    provides a comprehensive view of the chat execution lifecycle.
    """

    last_agent: Agent
    """Agent that produced the final response in this execution."""

    new_messages: list[Message]
    """Output messages generated by agents during this execution."""

    all_messages: list[Message]
    """Complete conversation history including both input and output messages."""

    agent_responses: list[AgentResponse]
    """All agent responses collected during execution, including intermediate steps."""


class RAGStrategyConfig(BaseModel):
    """Configuration for the RAG (Retrieval-Augmented Generation) optimization strategy.

    This class defines parameters for controlling how relevant messages are retrieved
    and selected during context optimization. It allows customization of the search
    query, result limits, relevance thresholds, and embedding model selection.

    Example:
        ```python
        config = RAGStrategyConfig(
            query="weather in London",
            max_messages=10,
            score_threshold=0.6,
            embedding_model="text-embedding-3-small",
        )
        ```
    """

    query: str | None = None
    """The search query used to find relevant messages."""

    max_messages: int | None = None
    """Maximum number of messages to retrieve."""

    score_threshold: float | None = None
    """Minimum similarity score (0-1) for including messages."""

    embedding_model: str | None = None
    """Name of the embedding model to use for semantic search."""
